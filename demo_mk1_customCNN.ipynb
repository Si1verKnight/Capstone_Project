{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 481 images belonging to 5 classes.\n",
      "Found 118 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset and apply data augmentation\n",
    "data_dir = 'C:\\Vijay\\Capstone\\Dataset'\n",
    "img_height, img_width = 256, 256\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "'''\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    validation_split=0.2\n",
    ")\n",
    "'''\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "15/15 [==============================] - 54s 4s/step - loss: 2.8437 - accuracy: 0.3430 - val_loss: 2.1048 - val_accuracy: 0.2708\n",
      "Epoch 2/25\n",
      "15/15 [==============================] - 72s 5s/step - loss: 1.2256 - accuracy: 0.5100 - val_loss: 2.3112 - val_accuracy: 0.2917\n",
      "Epoch 3/25\n",
      "15/15 [==============================] - 74s 5s/step - loss: 1.0739 - accuracy: 0.6013 - val_loss: 1.7879 - val_accuracy: 0.2708\n",
      "Epoch 4/25\n",
      "15/15 [==============================] - 78s 5s/step - loss: 0.8632 - accuracy: 0.6548 - val_loss: 1.7377 - val_accuracy: 0.2708\n",
      "Epoch 5/25\n",
      "15/15 [==============================] - 78s 6s/step - loss: 0.8664 - accuracy: 0.6592 - val_loss: 2.1055 - val_accuracy: 0.3958\n",
      "Epoch 6/25\n",
      "15/15 [==============================] - 76s 5s/step - loss: 0.8077 - accuracy: 0.6993 - val_loss: 1.8081 - val_accuracy: 0.4167\n",
      "Epoch 7/25\n",
      "15/15 [==============================] - 77s 5s/step - loss: 0.8443 - accuracy: 0.6904 - val_loss: 2.9549 - val_accuracy: 0.2500\n",
      "Epoch 8/25\n",
      "15/15 [==============================] - 74s 5s/step - loss: 1.0542 - accuracy: 0.6080 - val_loss: 2.2522 - val_accuracy: 0.2083\n",
      "Epoch 9/25\n",
      "15/15 [==============================] - 77s 5s/step - loss: 0.9218 - accuracy: 0.6303 - val_loss: 2.0632 - val_accuracy: 0.4271\n",
      "Epoch 10/25\n",
      "15/15 [==============================] - 78s 5s/step - loss: 0.7857 - accuracy: 0.7082 - val_loss: 2.4301 - val_accuracy: 0.3646\n",
      "Epoch 11/25\n",
      "15/15 [==============================] - 73s 5s/step - loss: 0.7998 - accuracy: 0.6993 - val_loss: 1.9295 - val_accuracy: 0.4375\n",
      "Epoch 12/25\n",
      "15/15 [==============================] - 72s 5s/step - loss: 0.8024 - accuracy: 0.7216 - val_loss: 2.0175 - val_accuracy: 0.3438\n",
      "Epoch 13/25\n",
      "15/15 [==============================] - 80s 5s/step - loss: 0.6898 - accuracy: 0.7500 - val_loss: 2.1704 - val_accuracy: 0.4583\n",
      "Epoch 14/25\n",
      "15/15 [==============================] - 78s 6s/step - loss: 0.7334 - accuracy: 0.7194 - val_loss: 2.7527 - val_accuracy: 0.4062\n",
      "Epoch 15/25\n",
      "15/15 [==============================] - 78s 5s/step - loss: 0.6779 - accuracy: 0.7327 - val_loss: 2.3681 - val_accuracy: 0.4167\n",
      "Epoch 16/25\n",
      "15/15 [==============================] - 80s 5s/step - loss: 0.6446 - accuracy: 0.7646 - val_loss: 2.5340 - val_accuracy: 0.3750\n",
      "Epoch 17/25\n",
      "15/15 [==============================] - 76s 5s/step - loss: 0.7094 - accuracy: 0.7550 - val_loss: 2.5628 - val_accuracy: 0.4792\n",
      "Epoch 18/25\n",
      "15/15 [==============================] - 75s 5s/step - loss: 0.7047 - accuracy: 0.7327 - val_loss: 2.1741 - val_accuracy: 0.5000\n",
      "Epoch 19/25\n",
      "15/15 [==============================] - 75s 5s/step - loss: 0.6044 - accuracy: 0.7929 - val_loss: 2.0004 - val_accuracy: 0.5312\n",
      "Epoch 20/25\n",
      "15/15 [==============================] - 78s 5s/step - loss: 0.9490 - accuracy: 0.6592 - val_loss: 3.3300 - val_accuracy: 0.2396\n",
      "Epoch 21/25\n",
      "15/15 [==============================] - 76s 5s/step - loss: 0.8889 - accuracy: 0.6837 - val_loss: 2.2373 - val_accuracy: 0.3854\n",
      "Epoch 22/25\n",
      "15/15 [==============================] - 73s 5s/step - loss: 0.7099 - accuracy: 0.7439 - val_loss: 2.4874 - val_accuracy: 0.4062\n",
      "Epoch 23/25\n",
      "15/15 [==============================] - 76s 5s/step - loss: 0.6807 - accuracy: 0.7461 - val_loss: 2.7675 - val_accuracy: 0.4375\n",
      "Epoch 24/25\n",
      "15/15 [==============================] - 76s 5s/step - loss: 0.6320 - accuracy: 0.7706 - val_loss: 2.3090 - val_accuracy: 0.4479\n",
      "Epoch 25/25\n",
      "15/15 [==============================] - 77s 5s/step - loss: 0.6401 - accuracy: 0.7929 - val_loss: 2.3530 - val_accuracy: 0.4167\n"
     ]
    }
   ],
   "source": [
    "# Define the custom CNN filter model\n",
    "def custom_cnn_filter(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Instantiate the model and compile it\n",
    "input_shape = (img_height, img_width, 3)\n",
    "model = custom_cnn_filter(input_shape)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 25\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('fabric_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
