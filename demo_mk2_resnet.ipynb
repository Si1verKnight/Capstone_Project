{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 481 images belonging to 5 classes.\n",
      "Found 118 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and apply data augmentation\n",
    "data_dir = 'C:\\Vijay\\Capstone\\Dataset'\n",
    "img_height, img_width = 256, 256\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 base model without the top classification layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Create a custom CNN filter using the ResNet architecture\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(5, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the base model and custom layers\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model to preserve the pre-trained weights\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "15/15 [==============================] - 72s 5s/step - loss: 2.1218 - accuracy: 0.2205 - val_loss: 1.7128 - val_accuracy: 0.1562\n",
      "Epoch 2/25\n",
      "15/15 [==============================] - 70s 5s/step - loss: 1.7291 - accuracy: 0.3029 - val_loss: 1.6557 - val_accuracy: 0.2292\n",
      "Epoch 3/25\n",
      "15/15 [==============================] - 56s 4s/step - loss: 1.6016 - accuracy: 0.3000 - val_loss: 1.5480 - val_accuracy: 0.4375\n",
      "Epoch 4/25\n",
      "15/15 [==============================] - 53s 4s/step - loss: 1.5252 - accuracy: 0.3474 - val_loss: 1.5430 - val_accuracy: 0.1979\n",
      "Epoch 5/25\n",
      "15/15 [==============================] - 57s 4s/step - loss: 1.4915 - accuracy: 0.3562 - val_loss: 1.5053 - val_accuracy: 0.3229\n",
      "Epoch 6/25\n",
      "15/15 [==============================] - 55s 4s/step - loss: 1.4242 - accuracy: 0.4254 - val_loss: 1.5319 - val_accuracy: 0.3542\n",
      "Epoch 7/25\n",
      "15/15 [==============================] - 55s 4s/step - loss: 1.4008 - accuracy: 0.4232 - val_loss: 1.5582 - val_accuracy: 0.2917\n",
      "Epoch 8/25\n",
      "15/15 [==============================] - 88s 6s/step - loss: 1.4334 - accuracy: 0.3786 - val_loss: 1.5223 - val_accuracy: 0.2604\n",
      "Epoch 9/25\n",
      "15/15 [==============================] - 96s 6s/step - loss: 1.4338 - accuracy: 0.3608 - val_loss: 1.5412 - val_accuracy: 0.3333\n",
      "Epoch 10/25\n",
      "15/15 [==============================] - 100s 7s/step - loss: 1.4248 - accuracy: 0.3875 - val_loss: 1.5803 - val_accuracy: 0.2917\n",
      "Epoch 11/25\n",
      "15/15 [==============================] - 102s 7s/step - loss: 1.3952 - accuracy: 0.4321 - val_loss: 1.5586 - val_accuracy: 0.3542\n",
      "Epoch 12/25\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.3823 - accuracy: 0.4209 - val_loss: 1.5458 - val_accuracy: 0.2812\n",
      "Epoch 13/25\n",
      "15/15 [==============================] - 61s 4s/step - loss: 1.4045 - accuracy: 0.4143 - val_loss: 1.5597 - val_accuracy: 0.2917\n",
      "Epoch 14/25\n",
      "15/15 [==============================] - 73s 5s/step - loss: 1.3452 - accuracy: 0.4208 - val_loss: 1.5581 - val_accuracy: 0.4062\n",
      "Epoch 15/25\n",
      "15/15 [==============================] - 60s 4s/step - loss: 1.3204 - accuracy: 0.4655 - val_loss: 1.5891 - val_accuracy: 0.3542\n",
      "Epoch 16/25\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.3393 - accuracy: 0.4410 - val_loss: 1.5555 - val_accuracy: 0.3854\n",
      "Epoch 17/25\n",
      "15/15 [==============================] - 61s 4s/step - loss: 1.3331 - accuracy: 0.4610 - val_loss: 1.5831 - val_accuracy: 0.2083\n",
      "Epoch 18/25\n",
      "15/15 [==============================] - 61s 4s/step - loss: 1.3289 - accuracy: 0.4543 - val_loss: 1.5788 - val_accuracy: 0.2292\n",
      "Epoch 19/25\n",
      "15/15 [==============================] - 59s 4s/step - loss: 1.2991 - accuracy: 0.4610 - val_loss: 1.5623 - val_accuracy: 0.4167\n",
      "Epoch 20/25\n",
      "15/15 [==============================] - 62s 4s/step - loss: 1.2888 - accuracy: 0.4477 - val_loss: 1.5632 - val_accuracy: 0.3542\n",
      "Epoch 21/25\n",
      "15/15 [==============================] - 60s 4s/step - loss: 1.2686 - accuracy: 0.4766 - val_loss: 1.6101 - val_accuracy: 0.4792\n",
      "Epoch 22/25\n",
      "15/15 [==============================] - 59s 4s/step - loss: 1.2923 - accuracy: 0.4566 - val_loss: 1.5401 - val_accuracy: 0.3229\n",
      "Epoch 23/25\n",
      "15/15 [==============================] - 61s 4s/step - loss: 1.2632 - accuracy: 0.4900 - val_loss: 1.6477 - val_accuracy: 0.3854\n",
      "Epoch 24/25\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.2793 - accuracy: 0.4766 - val_loss: 1.6069 - val_accuracy: 0.3646\n",
      "Epoch 25/25\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.2733 - accuracy: 0.4722 - val_loss: 1.6004 - val_accuracy: 0.2604\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 25\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('fabric_classification_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
